% abstract / resume
\begin{abstract}
  Pokemon battles represent a complex and high-variance environment that is influenced by a wide range of mechanics such as 
  type advantages, status effects and probabilistic events like move accuracy and critical hits. This project 
  investigates whether reinforcement learning can be used to optimize strategies within such an environment, and 
  whether knowledge gained from a trained agent can help human players improve their decision-making in Pokemon battles. 
  The study uses Deep Q-Networks (DQN) implemented with PyTorch and Gymnasium to train agents capable of playing Pokemon 
  battles. A custom battle simulator was developed to overcome the limitations of third-party environments and to provide 
  a fully controllable and extensible environment. The report details the design, implementation and iterative 
  development of both the agents and the environment, including handling of game mechanics, state representation 
  and reward functions. Evaluation includes agent performance over 10.000 self-play episodes 
  and profiling of the systems performance. The project concludes with reflections on learned agent behavior, performance 
  bottlenecks and opportunities for future improvement.
\end{abstract}
