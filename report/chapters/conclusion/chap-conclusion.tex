\chapter{Conclusion}
\label{chap:conclusion}

This project set out to explore whether reinforcement learning could be effectively applied to the complex and highly variable
environment of Pokemon battles. Through the development of a Deep Q-Network (DQN) agent and the construction of a custom
battle simulator, we have demonstrated that it is indeed possible to train an agent capable of engaging in
strategic decision-making within the Pokemon domain.

The project progressed through multiple iterations, starting with the use of 3rd party libraries like poke-env, and eventually
transitioning to a fully custom environment. This shift allowed for greater control over the simulation, improved performance
and the ability to tailor the environment specifically for reinforcement learning. A detailed implementation of game mechanics,
including various move effects, advanced battle logic and reward structures, enabled a vastly improved training process.

Training the agent through self-play over 10.000 episodes revealed positive learning trends and demonstrated the emergence of
informed behavior. Although reward parameters were sparse and the environment complexity posed various challenges, the agent displayed
signs of improvement and adaptation. Performance profiling further highlighted computational bottlenecks that then guided our future
optimization efforts.

The project also had a goal to provide a quick way to calculate the odds of a player winning a match given two teams of Pokemon.
The groundwork was done for this goal, but ultimately wasn't quite fleshed out enough to be usuable, due to a lack of userfacing
interface and API. 

Finally, this project validates the use of reinforcement learning for decision-making in turn-based, stochastic environments
like Pokemon battles. It also showcases the importance of simulation quality, effective reward design and iterative development 
processes when training AI agents. Future work could expand upon this foundation by introducing more advanced learning 
algorithms or integrating a GUI for analysis and human interactions.

