\section{Iteration 1}
\label{sec:Iteration-1-Agent-Environment}

The first iteration of the implementation focuses on having a minimum viable product \(MVP\). The MVP
consists of all MUST (M) requirements, which can be used as a baseline for next iterations.
Look chapter \ref{sec:functional-requirements} for a complete list of the MUST have requiremetns.
The MVP consists of a custom agent, with a custom training loop, that plays against a poke-env random agent,
in a generation 9, single battle pokemon showdown environment, where held items are available. 

\subsection{Poke-env Library}
The backboen of the first iteration of implementation is the Poke-env library. 
Poke-env provides packages to define environments and custom reinforcement learning agents. 
The library is designed to connect to a local or remote version of Pokemon showdown environment, 
where poke-env defines the parameters of the environment, such as the generation and battle format.


\subsection{Agent}
The agent is a custom implementation of the Poke-env player class and is designed to learn through 
a Deep Q-Network (DQN) algorithm with PyTorch. 


