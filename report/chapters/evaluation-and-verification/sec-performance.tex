\section{Performance evaluation}
\label{sec:performance-evaluation}

\subsection{Profiling}
\label{sec:profiling}
To evaluate the performance of the environments, the \lstinline|cProfile| module was used to collect detailed runtime statistics during a training loop. 
Profiling was done on both the custom environment and the Poke-env implementation. The results highlighted the most time-consuming functions and provided 
insights into where computational resources were being spent. It also showed how much time it took to run a training loop for both environments.
Each profiling test was performed over a 1000 episode training session to make sure each environment performed the same amount of work.

Poke-env used 311 seconds to complete 1000 episodes. When inspecting the cProfile output there was a notably large amount of time spent on serialization.
Almost half of the execution time was used on serialization, however it was only called one time. This could suggest that the serialization process involves 
handling a large amount of data or complex objects, resulting in a significant overhead during that single call. It may also indicate that the 
observations being serialized is particularly large, leading to a longer processing time. 

Following the serialization there was a lot of time spent inside the torch tensor functions used for the actual training portion of the program. Of the Poke-env
functions there are a notable amount of calls to parsing the Pokemon in battle. Over the course of 1000 episodes, there were 338913 calls to \lstinline|from_pokemon|, 
a function that parses a Pokemon from the showdown runtime to an observation. This introduces a lot of overhead to the program and could be an entryway
to optimizing the performance of Poke-env. The cProfile can be found in appendix \ref{appendix:poke-env-cprofile}.

The custom environment used 72 seconds to complete 1000 episodes. The cProfile shows that the majority of the runtime was spent in the 
action selection and encoding functions. In constrast with Poke-env, the custom environment spends more of its time actually doing the machine learning.
The \lstinline|from_pokemon| equivalent function in the custom environment is the Pokemon \lstinline|encode| function. It is similarly to Poke-env being
called a lot of times, but only has 251568 total calls. This is approximately 25\% fewer calls than Poke-env. This could also be an entryway for optimization.
The cProfile for the custom environment can be found in appendix \ref{appendix:custom-env-cprofile}. 

To summarize the profiling results: A lot of time is spent on converting rich data, like Python classes, into primitives that can easily be processed
by the GPU. Overall the custom environment was able to process episodes much faster than its Poke-env counterpart, but ran into similar bottlenecks.

\subsection{Identified bottlenecks}
\label{sec:bottlenecks}
By profiling the program runtimes a few bottlenecks were found with regards to performance.
Both Poke-env and the custom environment had issues that limited their speed. Notably, both environments are
largely CPU-bound. This means that, even though the processing related to the learning part is largely handled by the GPU, it is often
limited by how much data the CPU can provide. Each episode needs to be processed by the CPU in both environments. In the profiling section (see \ref{sec:profiling}), 
it was discovered that a lot of the program runtime was spent on converting rich data to GPU friendly primitive data. To mitigate this, multi-threading could
be applied to split the workload of encoding data across multiple CPU threads. This could significantly improve performance by making tasks run in parallel, rather than
in sequence. Another approach to this problem could be batching the processing and prepare more training data at once for the GPU to handle.
Both solutions could be used in tandem to further improve the efficiency of the program.

